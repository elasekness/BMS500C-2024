## Tutorial 2

**Objective:** To perform reference-based assemblies for actin, Hsp70, and ssu genes.

Our NGS data contains sequences from both _Cryptosporidium_ and contamination (such as bacteria and fungi) as
most of these samples were amplified from stool. You will map reads to your reference libraries to filter contaminants
from the reads of interest.  We will thenn generate de novo assemblies with our filtered reads, with the goal
of assembling our actin, Hsp70, and ssu amplicons for species typing.
Additionally, we will employ and compare the results of different methods to generate our consensus genomes.
Finally, you will learn about Docker for running bioinforamtics software.
<br>


## Some general information

Our read data are in fastq format. Fastq files contain the quality score for each nucleotide in the read and each read has four lines associated with it:

<br>

	@SRR10971381.1 1 length=151
	AGTCGATCAGCTGAGTACTAGTAGCATG
	+
	BBBCCCKKIBCCKKBIJDFFHHHIIJKK

> The read name, naming conventions may vary but names are always prefaced by '@'<br>
> This is followed by the sequence line <br>
> `+` a Line break <br>
> Followed by quality scores for each nucleotide in ASCII format

<br>

Each base has an associated quality score, which indicates the reliability of that call.
Phred scores are equal to -10 log<sub>10</sub>P, where P is the error probability for the base in question.
Thus, a phred score of 10 is equal to an error probability of 0.01 (P=10<sup>â€“Q/10</sup>) or a 1 in 10 chance that the base call is incorrect.

Most NGS output is in fastq format.  We are working with short, paired-end reads (2x250 bp or 2x150 bp)
generated by Illumina sequencers (such as MiSeq, NextSeq, or HiSeq).
While Illumina reads are shorter than those from traditional Sanger sequencing, Illumina sequencing can produce millions to hundreds of millions of reads per sample.
<br>


## General workflow for producing a reference-based assembly

Reference-based assemblies rely on a reference genome on which to map the reads of a genomic library.
Reference assemblies allow the direct comparison of a genome (in our case genes) of interest to an already-assembled genome (or genes). 
Typically, reference-based assemblies are employed for for SNP and/or Indel detection.

A general workflow for generating a reference-based assembly is given below:

<br>

**Quality control**

  - Generate some summary statistics with FastQC or seqkit

**Adaptor removal (and primer removal) and quality trimming**

 - cutadapt
 - Trimmomatic
 - BBduk from BBtools
 - FastX-toolkit
 - TrimGalore
 - Seqyclean
 - fastp
 - FaQCs
 - And many more

**Read alignment or mapping to reference genome**

 - BWA
 - Bowtie
 - BBmap
 - STAR (for RNA-Seq)

**General statistics pertaining to reference assembly**

 - Samtools
 - Picard
 - BBtools
 - Quast
 - Qualimap

**SNP and INDEL calling**

 - Samtools/bcftools
 - GATK
 - FreeBayes
 - iVAR (for viruses)
 - octopus (for polyploid genomes)

**Additional SNV filtering and annotation**

- bcftools
- GATK

<br>


## Sample assignment and metadata

Each student will map the paired-end (PE) fastqs from one sample to the reference database for downstream analyses.

| Student | Sample name |
| ------- | ------------|
| Student1 | 1 |
| Student2 | 2 |
| Student3 | 3 |
| Student4 | 4 |
| Student5 | 5 |
| Student6 | 6 |
| Student7 | 7 |
| Student8 | 8 |
| Student9 | 9 |
| Student 10 | 10 |

<br>

Copy the fastq files for your sample from the `BMS500C-2024` directory to your `fastq` directory. Assuming you're in your home directory an example command would look like this:

	cp ../BMS500C-2024/fastq/1_R*fastq.gz fastq/

> Replace `1` with the letter of your sample. <br>
> Notice that fastq files have either an _1 or _2 in their names, representing the forward and reverse direction of the sequencing.

<br>


## Adaptor removal and quality trimming

Remove adapters from your reads and keep only those reads passing quality metrics.

	trim_galore -q 30 --length 100 --paired --basename wnv[A-G] wnv[A-G]_1.fastq wnv[A-G]_2.fastq

> Adapters are short oligonucleotides ligated to a library for sequencing on Illumina machines. The reads in the _1 files are generated by sequencing that extends from the read 1 adapter to the read 2 adapter in the 5'-3' direction while the reads in the _2 file are those generated by extending from the read 2 adapter to the read 1 adapter in the 5'-3' direction. 
> Adapters are typically removed by the sequencing core but some may still remain. We might also want to remove reads that fall below a certain average quality or length. <br>
> Before running trim_galore, explore the options available to you with the help command. Most default setting are fine.
> Here we are using the default quality threshold of 30 (if we used the default of 20 we wouldn't have to specify it) and a minimum sequence length of 100. <br>
> **`Paired`** keeps 1 and 2 reads in order.  In other words, if one of the pairs fails quality control, both are removed. <br>
> The nice thing about TrimGalore is it pretty much does everything for you automatically, including detecting the type of adapter present 
> It also prints some summary statistics to STDOUT. <br>
> Trimmed reads are now in fastq files with the specified basename: `[1-10]_val_1.fastq` and `[1-10]_val_2.fastq`

* Judging from the TrimGalore output, does your sequencing run look good?
* What is the percentage of reads that passed trimming?
* You can also look at the quality with [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)


<br>


## Mapping trimmed reads to the reference genome

We will map our trimmed reads to our actin, Hsp70, and ssu genes with [BWA](http://bio-bwa.sourceforge.net">http://bio-bwa.sourceforge.net) (Burrows-Wheeler Aligner), a short-read aligner tool. Most short-read aligners rely on breaking reads into K-mers (shorter sequences of a specified length), aligning these to the reference genome, and extending these seeds with some amount of base misincorporation. This is actually faster than aligning the entire read. BWA outputs the alignment information in a [SAM](https://samtools.github.io/hts-specs/SAMv1.pdf) format. The output from BWA will need to be saved in a file, converted to a binary format, and sorted by read position in the genome (or coordinate) for additional analyses, such as variant calling.  While we could do each step individually, we can also pipe these commands together for faster processing and to avoid generating intermediate files that we would later delete.

<br>

Create an index of your reference genome.

	bwa index reference.fasta

 > Notice the additional files created with this command. Indexing is employed to improve the speed of the mapping algorithm. You can think of it as a look-up table that allows you to more efficiently identify the location of shorter sequences (your kmers) in a longer sequence.

<br>

Align your reads to the reference genome with BWA, pipe the output to samtools to sort the reads by their coordinates and to convert to a binary format. Note that we could also use compressed fastq files.

	bwa HQ596519.fasta wnv[A-G]_val_1.fastq wnv[A-G]_val_2.fastq | samtools sort -o wnv[A-G].sorted.bam

<br>

You can view the alignment file with `samtools`.  The [SAM](https://samtools.github.io/hts-specs/SAMv1.pdf) file is yet another tab delimited file where each line contains information on the read or its mate, mapping location, mapping quality, etc.

	samtools view wnv[A-G].sorted.bam | more

> We pipe the output of the `samtools` command to `more` for easier viewing.
> This is a good time to practice using `cut`, `sort`, and `uniq` commands for getting a quick sense of your data.
* Can you get a sense of the average mapping quality of your reads? **Hint**: mapping quality is contained in the 5th field.

<br>

Now generate some summary statistics for your alignment file.

	samtools flagstat wnv[A-G].sorted.bam

> This command provides some useful information on the number of reads that mapped or didn't map to your reference
> genome, how many R1 and R2 reads mapped, and how many mates are properly paired with each other
* Do you think the reference genome was an appropriate choice for your WNV library?

<br>

Determine coverage and depth of coverage.

	samtools coverage wnv[A-G].sorted.bam

* Based on average read depth, genome coverage, and mean mapping quality, do you think you have a high-quality alignment?

<br>

Now let's try an alternative way of calculating average read depth.

	samtools depth -aa wnv[A-G].sorted.bam > wnv[A-G].depth.txt

> We use the **`-aa`** flag to indicate that we want all positions in the output, including those with zero-depth. <br>
> We use **`-d 0`** to indicate that we don't want a depth limit (the default cuts the depth off at 8000 reads). <br>
> Once again, we have a tab delimited file specifying the contig name, the position, and the depth.

<br>

Now use `awk` to cut the third field, add each successive line to the last, and divide the sum by the length of the reference genome.

	awk -F '\t' '{sum += $3} END {print sum/11209}' wnv[A-G].depth.txt

> AWK is a scripting language that allows you to parse a file line by line and perform some operation on those parsed lines based on the statement provided in the **`awk`** command. <br>
> Here, we are specifying a field **`-F`** to search, which is a tab **`\t`**. <br>
> The next statement indicates that we should take the third field of each line **`$3`** and add the value in this field to a variable called **`sum`**.  The **`$3`** is itself a variable for the content of each third field encountered by awk. <br>
> We end the statement and then issue another statement to print the sum divided by the length of the reference genome, which is 11209 base pairs. <br>
> The syntax for an `awk` statement is below (and see here for more on [awk](https://www.geeksforgeeks.org/awk-command-unixlinux-examples/):

	awk options 'selection_criteria {action}' file
 
* Does the average depth you calculated match the result from `samtools`?

<br>


## Single nucleotide variant (SNV) calling
A single nucleotide variant (SNV) is a substitution of one nucleotide for another with respect to our reference genome. A single nucleotide polymorphism (SNP) is an SNV present in at least 1% of the population but the terms are often used interchangeably.  Other types of variation include insertions and deletions (INDELS), which we will not be identifying. There are several tools that will perform variant calling.  

<br>

We will use [Bcftools](https://samtools.github.io/bcftools/).

	bctools mpileup -q 30 -d 100000 -f HQ596519.fasta wnv[A-Z].sorted.bam | bcftools call -m -v -V indels --ploidy 1 > wnv[A-Z].vcf

> The `mpileup` function calculates genotype likelihoods and the `call` function uses this information to call variants. <br>
> **`-q`** specifies the minimum mapping quality for an alignment to be considered <br>
> **`-d`** specifies the maximum depth to read at each position <br>
> **`-f`** indicates the reference genome <br>
> **`-m`** = multi-allelic variant caller <br>
> **`-v`** = output only variant positions (i.e. not those that match the reference nucleotide) <br>
> **`-V`** = do not consider INDELs <br>
> Notice that the output is in the tab delimited [VCF](https://samtools.github.io/hts-specs/VCFv4.2.pdf) format.

<br>

Take a look at your vcf file. The begining of the file is devoted to descriptions of the information contained therein; these lines being with a '#'.  After each line contains information on a position with a variant call, including the reference contig, the position, the reference and alternative nucleotides at this position, and the quality of the call (bigger is better). The 'Format' field contains additional information that you can use to assess whether the variant call is real or a false positive (for example, do to a poor assembly or a repetitive region). The four numbers after `DP4` indicate the number of high quality forward and reverse reads that support the reference nucleotide and the number of forward and reverse reads that support the alternative, respectively. 

Do all variant calls appear to be high-quality or should some be excluded?  Would we want to include low-frequency variants in a consensus genome?

<br>

There are many different criteria you could use to filter a vcf file. And these criteria will likely change depending on the goals of the project and the organism or population of study.  Let's use another function of `bcftools` to filter our vcf files by minimum quality and depth criteria.

	bcftools query -i 'QUAL>220 && DP>100' -f '%POS\t%REF\t%ALT\t%QUAL\n' wnv[A-G].vcf

 > **`-i`** specifies the filtering criteria.  We want a quality value greater than 220 and a depth value greater than 100 <br>
 > **`-f`** specifies the fields we want output to STDOUT.  In this case, we want to see the position, reference and alternative alleles, and the quality value, seperated by a tab `\t`.
* How many variants are high-quality?
* How many variants are in your vcf?
* Are there still low frequency variants that you would exclude?
* Can you create a command with grep, sed, and awk that would grab the F and R depths for REF and ALT and calculate the frequency of ALT? Don't peak but here is the [answer](https://github.com/elasekness/BMS500C/blob/main/Answers.md).

<br>

Now let's generate our consesus genome sequence. The first steps are two index our reference genome and compress and index our vcf file.

	samtools faidx HQ596519.fasta
 	bcftools convert -O z wnv[A-G].vcf -o wnv[A-G].vcf.gz
  	bcftools index wnv[A-G].vcf.gz
   	bcftools consensus -H A -i 'QUAL>220 && DP>100' -f HQ596519.fasta -p wnv[A-G]_ wnv[A-G].vcf.gz > wnv[A-G].fasta

> The **`-O`** in the **`bcftools convert`** command specifies the format of the output, which is `z` for compressed vcf
> The **`-H`** in the **`bcftools consensus`** command specifies that we want to apply the alternative **`A`** allele to our consensus genome. <br>
> The **`-i`** selects sites which meet the filtering criteria specified (the same as in our query statement). <br>
> The **`-p`** appends a prefix to the name of our consensus sequence (otherwise it will be named for the reference). <br>
> Essentially, we are using the reference as a backbone for our consensus sequence and subsituting the alternative nucleotide at variant positions.  Unfortunately, with this strategy, positions with no coverage are assigned the reference nucleotide, which may or may not be correct.

<br>

Now try using [iVar](https://github.com/andersen-lab/ivar) -a tool designed for viral assemblies- to generate a consensus genome. But before we do, let's talk about Docker containers.

<br>


## Docker

A Docker container image is essentially like a little VM that contains code for an application and all of its dependencies. Thus, Docker containers should run the same way on any Linux machine. This is valuable because software is often difficult to compile from source code.  Docker containers also eliminate issues with versioning, such that you can run docker containers of multiple versions of the same program without running into problems with conflicting dependencies. A docker image is the static instructions for making the running container. The image creates the container instance. Conveniently, Docker has already been installed for us on our machines.

Docker images can be 'pulled' from repositories on [Docker hub](https://hub.docker.com/) 
Anyone with a Docker account can create a repository for software that they have containerized.
Two repositories that I pull from frequently are [staphb](https://github.com/StaPH-B/docker-builds) and 'biocontainers.'

Two commands that you will use are **`docker pull`** and **`docker run`**

The command: **`docker pull staphb/ivar`**, will pull the latest image of iVar from the staphb repository registered on Docker Hub.
You can specify another version with tags: **`docker pull staphb/spades:3.12.0`**, pulls an image for spades (a de novo assembler) version 3.12.0
<br>
The **`docker run`** command will:
* initiate Docker client talking to docker daemon
* pull image if not found locally by Docker daemon
* start new container from image (i.e. run the image as a container)
* execute specified command
<br>
The docker run command essentially converts our image to a container.  To actually execute our command
on our files, we need to make them visible to the container.  Thus, we must mount a working directory inside the VM. To do this, we will use two arguments with our run command:

**`-v $(pwd):/data`** mounts our current directory to the VM (it will also create a directory called 'data' if it doesn't exist).
**`-w /data`** allows the command being executed to run in the directory specified.

When the container runs, it's being run as the 'root' user. We can change this but the default is fine for now.
The only issue is that the output produced will be owned by 'root', not by us.  Thus, we will have read-only permissions.  This shouldn't generally be a problem because we aren't altering most of our output files, but we can always change the permissions with a **`sudo chmod`** command.

<br>

For an additional Docker tutorial see [https://github.com/PawseySC/bio-workshop-18](https://github.com/PawseySC/bio-workshop-18)

<br>

See what docker images are already on your VM.

	docker images

> You should see that the staphb image for ivar (staphb/ivar:latest) is already on our VMs.

<br>

You can run your docker container interactively (from within the container).  Let's do this to understand how iVar works.

	docker run --rm -it staphb/ivar

> You are now within the container, which has Linux, iVar, and all of iVar's dependencies installed.  Thus, we can use the same Bash commands that we've been using to navigate around the filesystem and bring up the iVar help menu by typing the `ivar` command. <br>
> **`-it`** = i for interactive mode, and t for emulating a terminal inside the container
> **`--rm`** removes the new container instead of storing it on your computer. <br>
> To exit the container, type: **`ctr-d`**.

<br>

You might have noticed that the `ivar consensus` command actually takes the output piped from samtools. This means we must issue two docker run commands to the staphb/ivar image and specify piped output with the `-i` argument. If ivar were install on our VMs, the command would look like this:

	samtools mpileup -aa -A -d 0 -Q 0 wnv[A-G].sorted.bam | ivar consensus -t 0.9 -m 100 -n N -p wnv[A-G]

> `samtools mpileup` is providing the genotype likelihoods <br>
> `ivar consensus` is creating the consensus sequence with the following parameters: <br>
> `-t` = minimum frequency threshold to call a consensus (alt or ref must be supported by this mininum) <br>
> `-m` = minimum depth to call a consensus <br>
> `-n` = if depth is below minimum, position is ambiguous <br>
> `-p` = prefix of fasta ouput file <br>

<br>

To run the dockerized version of this command, we need both `docker run` and `ivar` commands.

	docker run --rm -v $(pwd):/data -w /data staphb/ivar ivar mpileup -aa -A -d 0 -Q 0 wnv[A-G].sorted.bam | docker run -i --rm -v $(pwd):/data -w /data staphb/ivar ivar consensus -t 0.9 -m 100 -n N -p wnv[A-G]

> Your consensus genome will be saved in the fasta file, wnv[A-G].fa 

<br>

Compare the consensus genomes created by bcftools and ivar. We will first concatenate our two fasta files into a single file, align the genomes in both with [mafft](https://mafft.cbrc.jp/alignment/software/), and count the number of SNPs with [snp-dists](https://github.com/tseemann/snp-dists).

	cat wnv[A-G].fasta wnv[A-G].fa > both_genomes.fasta
 	mafft both_genomes.fasta > both_genomes.aln.fasta
  	snp-dists both_genomes.aln.fasta

> Our consensus genomes should be the same length so they should already be aligned but we'll align anyway for good practice. <br>
> By default **`snp-dists`** does not count ambiguous positions. <br>
* Were there any differences between these two genomes?
* Now include ambiguous positions in the tally.
* Did bcftools assign a reference call to a position that was considered ambiguous by iVar?

Generate assembly summary statistics with [quast](https://github.com/ablab/quast)

	docker run --rm -v $(pwd):/data -w /data staphb/quast quast.py -r HQ596519.fasta wnv[A-G].fasta wnv[A-G].fa

> `Quast` generates an output directory with a bunch of results.  `cd` to `quast_results/latest` and look at the `reports.txt` file
> The bcftools and iVar consensus genomes should look very similar except that iVar's contains ambiguous positions.
* How many mismatches/100 kb are there between your two consensus genomes and the reference?
