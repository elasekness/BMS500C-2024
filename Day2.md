## Tutorial 2

**Objective:** To perform reference-based and de novo assemblies for actin, Hsp70, and ssu genes.

Our NGS data contains sequences from both _Cryptosporidium_ and contamination (such as bacteria and fungi) as
most of these samples were amplified from stool. You will map reads to your reference libraries to filter contaminants
from the reads of interest.  We will thenn generate de novo assemblies with our filtered reads, with the goal
of assembling our actin, Hsp70, and ssu amplicons for species typing.
Additionally, we will employ and compare the results of different methods to generate our consensus genomes.
Finally, you will learn about Docker for running bioinforamtics software.
<br>


## Some general information

Our read data are in fastq format. Fastq files contain the quality score for each nucleotide in the read and each read has four lines associated with it:

<br>

	@SRR10971381.1 1 length=151
	AGTCGATCAGCTGAGTACTAGTAGCATG
	+
	BBBCCCKKIBCCKKBIJDFFHHHIIJKK

> The read name, naming conventions may vary but names are always prefaced by '@'<br>
> This is followed by the sequence line <br>
> `+` a Line break <br>
> Followed by quality scores for each nucleotide in ASCII format

<br>

Each base has an associated quality score, which indicates the reliability of that call.
Phred scores are equal to -10 log<sub>10</sub>P, where P is the error probability for the base in question.
Thus, a phred score of 10 is equal to an error probability of 0.01 (P=10<sup>â€“Q/10</sup>) or a 1 in 10 chance that the base call is incorrect.

Most NGS output is in fastq format.  We are working with short, paired-end reads (2x250 bp or 2x150 bp)
generated by Illumina sequencers (such as MiSeq, NextSeq, or HiSeq).
While Illumina reads are shorter than those from traditional Sanger sequencing, Illumina sequencing can produce millions to hundreds of millions of reads per sample.
<br>


## General workflow for producing a reference-based assembly

Reference-based assemblies rely on a reference genome on which to map the reads of a genomic library.
Reference assemblies allow the direct comparison of a genome (in our case genes) of interest to an already-assembled genome (or genes). 
Typically, reference-based assemblies are employed for for SNP and/or Indel detection.

A general workflow for generating a reference-based assembly is given below:

<br>

**Quality control**

  - Generate some summary statistics with FastQC or seqkit

**Adaptor removal (and primer removal) and quality trimming**

 - cutadapt
 - Trimmomatic
 - BBduk from BBtools
 - FastX-toolkit
 - TrimGalore
 - Seqyclean
 - fastp
 - FaQCs
 - And many more

**Read alignment or mapping to reference genome**

 - BWA
 - Bowtie
 - BBmap
 - STAR (for RNA-Seq)

**General statistics pertaining to reference assembly**

 - Samtools
 - Picard
 - BBtools
 - Quast
 - Qualimap

**SNP and INDEL calling**

 - Samtools/bcftools
 - GATK
 - FreeBayes
 - iVAR (for viruses)
 - octopus (for polyploid genomes)

**Additional SNV filtering and annotation**

- bcftools
- GATK

<br>


## Sample assignment and metadata

Each student will map the paired-end (PE) fastqs from one sample to the reference database for downstream analyses.

| Student | Sample name |
| ------- | ------------|
| Student1 | 1 |
| Student2 | 2 |
| Student3 | 3 |
| Student4 | 4 |
| Student5 | 5 |
| Student6 | 6 |
| Student7 | 7 |
| Student8 | 8 |
| Student9 | 9 |
| Student 10 | 10 |

<br>

Copy the fastq files for your sample from the `BMS500C-2024` directory to your `fastq` directory. Assuming you're in your home directory an example command would look like this:

	cp ../BMS500C-2024/fastq/1_R*fastq.gz fastq/

> Replace `1` with the letter of your sample. <br>
> Notice that fastq files have either an _R1 or _R2 in their names, representing the forward and reverse direction of the sequencing.

<br>

## Create database by concatenating our individual gene fasta files

We have separate fasta files for actin, Hsp70, and ssu.  We can concatenate these together to create a single database.
Using our `sed` command, let's also add the gene name to the definition line. We will discuss the `sed` syntax in class.<br>
Assuming you're in your home directory:

	sed 's/\(>.*\)/\1_actin/' actin/actin.fasta > fastq/reference.fasta
 	sed 's/\(>.*\)/\1_hps70/' hsp70/hsp70.fasta >> fastq/reference.fasta
  	sed 's/\(>.*\)/\1_ssu/' ssu/ssu.fasta > fastq/reference.fasta

> Notice that the `\(` and `\)` have special meaning. <br>
> Also notice that we are appending data to our reference.fasta file instead of overwriting that information with `.>>`. <br>
> We specified the relative path to our fasta files and wrote the output of the sed commands to reference.fasta, which is located in the `fastq` directory.

<br>

## Getting some basic read statistics

You can generate a summmary of the quality of your data with [fastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), which provides nice graphics or we can use
[SeqKit](https://bioinf.shenwei.me/seqkit/) for a more pared-down summary of our data.

	cd fastq/
	seqkit stats [1-10]_R1.fastq.gz
 	seqkit stats [1-10]_R2.fastq.gz

## Adaptor removal and quality trimming

Remove adapters from your reads and keep only those reads passing quality metrics.

	trim_galore -q 30 --length 100 --paired --basename [1-10] [1-10]_R1.fastq.gz [1-10]_R2.fastq.gz

> Adapters are short oligonucleotides ligated to a library for sequencing on Illumina machines. The reads in the _R1 files are generated by sequencing that extends from the read 1 adapter to the read 2 adapter in the 5'-3' direction while the reads in the _R2 file are those generated by extending from the read 2 adapter to the read 1 adapter in the 5'-3' direction. 
> Adapters are typically removed by the sequencing core but some may still remain. We might also want to remove reads that fall below a certain average quality or length. <br>
> Before running trim_galore, explore the options available to you with the help command. Most default setting are fine.
> Here we are using the default quality threshold of 30 (if we used the default of 20 we wouldn't have to specify it) and a minimum sequence length of 100. <br>
> **`Paired`** keeps 1 and 2 reads in order.  In other words, if one of the pairs fails quality control, both are removed. <br>
> The nice thing about TrimGalore is it pretty much does everything for you automatically, including detecting the type of adapter present 
> It also prints some summary statistics to STDOUT. <br>
> Trimmed reads are now in fastq files with the specified basename: `[1-10]_val_1.fastq` and `[1-10]_val_2.fastq`

* Judging from the TrimGalore output, does your sequencing run look good?
* What is the percentage of reads that passed trimming?
* Have the summary statistics changed for your trimmed reads in comparison to the original fastq files?


<br>


## Mapping trimmed reads to the reference

We will map our trimmed reads to our actin, Hsp70, and ssu genes with [BWA](http://bio-bwa.sourceforge.net">http://bio-bwa.sourceforge.net) (Burrows-Wheeler Aligner), a short-read aligner tool. Most short-read aligners rely on breaking reads into K-mers (shorter sequences of a specified length), aligning these to the reference genome, and extending these seeds with some amount of base misincorporation. This is actually faster than aligning the entire read. BWA outputs the alignment information in a [SAM](https://samtools.github.io/hts-specs/SAMv1.pdf) format. The output from BWA will need to be saved in a file, converted to a binary format, and sorted by read position in the genome (or coordinate) for additional analyses, such as variant calling.  While we could do each step individually, we can also pipe these commands together for faster processing and to avoid generating intermediate files that we would later delete.

<br>

Create an index of your reference genome.

	bwa index reference.fasta

 > Notice the additional files created with this command. Indexing is employed to improve the speed of the mapping algorithm. You can think of it as a look-up table that allows you to more efficiently identify the location of shorter sequences (your kmers) in a longer sequence.

<br>

Align your reads to the reference database with BWA, pipe the output to samtools to sort the reads by their coordinates and to convert to a binary format.

	bwa reference.fasta [1-10]_val_1.fq.gz [1-10]_val_2.fq.gz | samtools sort -o [1-10].sorted.bam

> We pipe the output of bwa to [samtools](http://www.htslib.org/) to sort the output by read coordinates and convert the sam file to a binary format (bam) <br>
> Although not really necessary to do so here, most other downstream analyses (such as variant detection) require a coordinate-sorted bam file so it's good practice.

<br>

You can also view the alignment file with `samtools`.  The [SAM](https://samtools.github.io/hts-specs/SAMv1.pdf) file is yet another tab delimited file where each line contains information on the read or its mate, mapping location, mapping quality, etc.

	samtools view [1-10].sorted.bam | more

> We pipe the output of the `samtools` command to `more` for easier viewing. <br>
> This is a good time to practice using `cut`, `sort`, and `uniq` commands for getting a quick sense of your data.
* Can you get a sense of the average mapping quality of your reads? **Hint**: mapping quality is contained in the 5th field.

<br>

Now generate some summary statistics for your alignment file.

	samtools flagstat [1-10].sorted.bam
 	samtools idxstat [1-10].sorted.bam

> This command provides some useful information on the number of reads that mapped or didn't map to your reference, how many R1 and R2 reads mapped, and how many mates are properly paired with each other. <br>
> idxstat shows how many reads aligned to each reference gene. <br>
* Can you get a sense of what the identity of your sample might be from the idxstats information?

<br>

Determine coverage and depth of coverage.

	samtools coverage [1-10].sorted.bam

* Based on average read depth, genome coverage, and mean mapping quality, can you get a sense of which species has been sequenced?

<br>


## Extract mapped reads with samtools fastq function

<br>

	samtools fastq -F 4  [1-10].sorted.bam -o [1-10].fastq

> The `-F 4` flag excludes reads that do not map to the reference database <br>
> Here, we wrote both F and R reads to the same fastq file <br>
> Notice that the samtools fastq help menu shows that we could write them to their own files. <br>

<br>

## Generate a de novo assembly with your extracted reads

We will use [Megahit](https://github.com/voutcn/megahit?tab=readme-ov-file) to perform a de novo assembly.

	megahit -r [1-10].fastq -o assembly

> The `-r` argument indicates that we have unpaired reads (as we put both R1 and R2 reads into the same fastq file). <br>
> The `-o` argument specifies a directory where the results will be written.
* How many contigs did you generate?

## Docker

A Docker container image is essentially like a little VM that contains code for an application and all of its dependencies. Thus, Docker containers should run the same way on any Linux machine. This is valuable because software is often difficult to compile from source code.  Docker containers also eliminate issues with versioning, such that you can run docker containers of multiple versions of the same program without running into problems with conflicting dependencies. A docker image is the static instructions for making the running container. The image creates the container instance. Conveniently, Docker has already been installed for us on our machines.

Docker images can be 'pulled' from repositories on [Docker hub](https://hub.docker.com/) 
Anyone with a Docker account can create a repository for software that they have containerized.
Two repositories that I pull from frequently are [staphb](https://github.com/StaPH-B/docker-builds) and 'biocontainers.'

Two commands that you will use are **`docker pull`** and **`docker run`**

The command: **`docker pull staphb/staphb`**, will pull the latest image of iVar from the staphb repository registered on Docker Hub.
You can specify another version with tags: **`docker pull staphb/spades:3.12.0`**, pulls an image for spades (a de novo assembler) version 3.12.0
<br>
The **`docker run`** command will:
* initiate Docker client talking to docker daemon
* pull image if not found locally by Docker daemon
* start new container from image (i.e. run the image as a container)
* execute specified command
<br>
The docker run command essentially converts our image to a container.  To actually execute our command
on our files, we need to make them visible to the container.  Thus, we must mount a working directory inside the VM. To do this, we will use two arguments with our run command:

**`-v $(pwd):/data`** mounts our current directory to the VM (it will also create a directory called 'data' if it doesn't exist).
**`-w /data`** allows the command being executed to run in the directory specified.

When the container runs, it's being run as the 'root' user. We can change this but the default is fine for now.
The only issue is that the output produced will be owned by 'root', not by us.  Thus, we will have read-only permissions.  This shouldn't generally be a problem because we aren't altering most of our output files, but we can always change the permissions with a **`sudo chmod`** command.

<br>

For an additional Docker tutorial see [https://github.com/PawseySC/bio-workshop-18](https://github.com/PawseySC/bio-workshop-18)

<br>

See what docker images are already on your VM.

	docker images


<br>

You can run your docker container interactively (from within the container).  Let's do this to understand how iVar works.

	docker run --rm -it staphb/spades

> You are now within the container, which has Linux, spades, and all of spades dependencies installed.  Thus, we can use the same Bash commands that we've been using to navigate around the filesystem and bring up the spades help menu by typing the `spades.py` command. <br>
> **`-it`** = i for interactive mode, and t for emulating a terminal inside the container
> **`--rm`** removes the new container instead of storing it on your computer. <br>
> To exit the container, type: **`ctr-d`**.

<br>

To run the dockerized version of this command, we need both `docker run` and `spades` commands.

	docker run --rm -v $(pwd):/data -w /data staphb/spades spades.py -s [1-10].fastq -o spades_assembly

> `-s` specifies our single-end reads.
* How many contigs did spades generate?
